{"cells":[{"cell_type":"markdown","metadata":{"id":"8trqjnsHBqft"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24663,"status":"ok","timestamp":1716113741837,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JT1BvkRYBuFX","outputId":"1a083293-d2ee-43a8-e55b-9a288383f9eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Drive mounted.\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bW4KeHLnDSuu"},"outputs":[],"source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM, Algorithm\n","from reprshift.models.hparams import hparams_f\n","from reprshift.models.networks import Featurizer, Classifier\n","from reprshift.dataset.datasets import MultiNLI, CivilComments\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader"]},{"cell_type":"markdown","metadata":{"id":"R2YjWbHd9fL4"},"source":["# LFF Algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idZLRy0MBfqt"},"outputs":[],"source":["import torch\n","from reprshift.models.networks import Featurizer, Classifier\n","from reprshift.learning.optimization import get_bert_optim\n","from transformers import get_scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7heQS6ze9ha-"},"outputs":[],"source":["# Todo: non-linear classifier (maybe?)\n","def NonLinearClassifier(in_features, out_features):\n","    return torch.nn.Sequential(\n","        torch.nn.Linear(in_features, in_features // 2),\n","        torch.nn.ReLU(),\n","        torch.nn.Linear(in_features // 2, in_features // 4),\n","        torch.nn.ReLU(),\n","        torch.nn.Linear(in_features // 4, out_features))\n","\n","# Based on: https://github.com/YyzHarry/SubpopBench\n","class LfF(Algorithm):\n","    \"\"\"\n","    Learning from Failure (LfF) [https://arxiv.org/pdf/2007.02561.pdf]\n","    \"\"\"\n","    def __init__(self, num_classes, num_attributes, hparams):\n","        super().__init__(num_classes, num_attributes, hparams)\n","\n","        self.pred_model = ERM(num_classes, num_attributes, hparams)\n","        self.biased_featurizer = Featurizer(hparams['last_layer_dropout'])\n","        cls_in_features = 768 #self.featurizer.featurizer.config.hidden_size #\n","        self.biased_classifier = NonLinearClassifier(cls_in_features, num_classes) # differently, we use a linear biased classifier\n","        self.biased_network = torch.nn.Sequential(self.biased_featurizer, self.biased_classifier)\n","        self.q = self.hparams['LfF_q']\n","        self._init_model()\n","\n","    def _init_model(self):\n","        lr, weight_decay, num_warmup_steps, num_training_steps = self.hparams['lr'], self.hparams['weight_decay'], self.hparams['num_warmup_steps'], self.hparams['num_training_steps']\n","        self.pred_model._init_model(lr, weight_decay, num_warmup_steps, num_training_steps)\n","\n","        self.clip_grad = True\n","        self.biased_network.zero_grad()\n","\n","        self.optimizer_b = get_bert_optim(self.biased_network, lr, weight_decay)\n","        self.lr_scheduler = get_scheduler(\"linear\",optimizer=self.optimizer_b,num_warmup_steps=num_warmup_steps,num_training_steps=num_training_steps)\n","\n","    # implemented from equation\n","    def GCE(self, logits, targets):\n","        p = torch.nn.functional.softmax(logits, dim=1)\n","        Yg = torch.gather(p, 1, torch.unsqueeze(targets, 1))\n","        loss = (1 - Yg.squeeze()**self.q) / self.q\n","        return loss\n","\n","    # copied from the authors' repo\n","    def GCE2(self, logits, targets):\n","        p = torch.nn.functional.softmax(logits, dim=1)\n","        Yg = torch.gather(p, 1, torch.unsqueeze(targets, 1))\n","        loss = torch.nn.functional.cross_entropy(logits, targets, reduction='none') * (Yg.squeeze().detach()**self.q)*self.q\n","        return loss\n","\n","    def update(self, minibatch, step):\n","        all_i, all_x, all_y, all_a = minibatch\n","        pred_logits = self.pred_model.predict(all_x)\n","        biased_logits = self.biased_network(all_x)\n","        loss_gce = self.GCE2(biased_logits, all_y)\n","        ce_b = torch.nn.functional.cross_entropy(biased_logits, all_y, reduction='none')\n","        ce_d = torch.nn.functional.cross_entropy(pred_logits, all_y, reduction='none')\n","        weights = (ce_b/(ce_b + ce_d + 1e-8)).detach()\n","\n","        self.optimizer_b.zero_grad()\n","        self.pred_model.optimizer.zero_grad()\n","\n","        loss_pred = (ce_d * weights).mean()\n","        loss = loss_pred.mean() + loss_gce.mean()\n","        loss.backward()\n","\n","        if self.clip_grad:\n","            torch.nn.utils.clip_grad_norm_(self.biased_network.parameters(), 1.0)\n","            torch.nn.utils.clip_grad_norm_(self.pred_model.parameters(), 1.0)\n","        self.optimizer_b.step()\n","        self.pred_model.optimizer.step()\n","\n","        self.lr_scheduler.step()\n","        self.pred_model.lr_scheduler.step()\n","\n","        self.biased_network.zero_grad()\n","        self.pred_model.zero_grad()\n","\n","        return {'loss': loss.item(), 'loss_pred': loss_pred.mean().item(), 'loss_gce': loss_gce.mean().item()}\n","\n","    def return_feats(self, x):\n","        return self.pred_model.featurizer(x)\n","\n","    def predict(self, x):\n","        return self.pred_model.predict(x)\n"]},{"cell_type":"markdown","metadata":{"id":"yOFYFzDCBwcm"},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":635,"status":"ok","timestamp":1716113772822,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"zmBfh47bCgJi","outputId":"49720341-3052-4fa1-874c-1fe2f94ab5b1"},"outputs":[{"data":{"text/plain":["{'batch_size': 16,\n"," 'last_layer_dropout': 0.5,\n"," 'optimizer': 'adamw',\n"," 'weight_decay': 0.0001,\n"," 'lr': 1e-05,\n"," 'group_balanced': False,\n"," 'num_training_steps': 30001,\n"," 'num_warmup_steps': 0,\n"," 'LfF_q': 0.7}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["hparams = hparams_f('LfF')\n","hparams"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuvFrU37u7V9"},"outputs":[],"source":["device = \"cuda\"\n","train_weights = None\n","batch_size = hparams['batch_size']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2413,"status":"ok","timestamp":1716113853976,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bpKbj3leBy8p","outputId":"b3516b96-c8c8-4667-a1cf-4ec19b0b212c"},"outputs":[{"name":"stdout","output_type":"stream","text":["CivilComments\n"]}],"source":["DATASET = 'CivilComments'  # 'CivilComments' , 'MultiNLI'\n","\n","if DATASET == 'MultiNLI':\n","    NUM_CLASSES = 3\n","    NUM_ATTRIBUTES = 2\n","    train_dataset = MultiNLI(data_path, 'tr', hparams)\n","    models_path = path_to_root + '/models/models_mnli'\n","    print(DATASET)\n","elif DATASET  == 'CivilComments':\n","    NUM_CLASSES = 2\n","    NUM_ATTRIBUTES = 8\n","    train_dataset = CivilComments(data_path, 'tr', hparams, granularity=\"fine\")\n","    models_path = path_to_root + '/models/models_civilcomments'\n","    print(DATASET)\n","else:\n","    print('Dataset Not Implemented')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1716113856695,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"iLwCfOsy2vyr","outputId":"62bcba79-638e-4b4c-f836-ec23b09cdd9e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}],"source":["train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                    weights=train_weights,\n","                                    batch_size=batch_size,\n","                                    num_workers=1)\n","steps_per_epoch = len(train_dataset) / batch_size"]},{"cell_type":"markdown","metadata":{"id":"wcXHpw2dB0VV"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBJ-qyGsB08z"},"outputs":[],"source":["algorithm_name = 'LfF'\n","random_seeds = [0,1,2] #[0,1,2]\n","init_state_dict_path = lambda random_seed : models_path + f'/00_randominit/seed{random_seed}/sd_epoch0.pth'\n","state_dict_PATH = models_path + '/07_lff/'"]},{"cell_type":"markdown","metadata":{"id":"7KIXqJyvB1g0"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564,"referenced_widgets":["05bd18d236274f11a7eb489c59823eb5","6dc40b9bbed54b198d75744b10698a68","852790756f464e719ebd8fa6b25ec5a5","c29fe13b3f1b48fa8b955d2f9f3ecee0","7dca342ad93a4afdbd0e9ce1e92b251d","c09bea900fc04f5ca9c5fbe6bf6b6e13","0babc266d395446b8e3a385a99b25272","51aa5a90bbe0437ba37d88322a3fd809","27f26a3740fe4ef3934bfbf0a36bfa3b","0c3803a64a3d45c4bf90e1a6f3550b4b","e2a93d8a445e4461a17c550b10f84f97"]},"executionInfo":{"elapsed":2043042,"status":"error","timestamp":1716124520446,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"6qZBmY3jB2ly","outputId":"5f5f5ba3-2fa2-4fe1-8e2b-06598af5bdd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Seed: 0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05bd18d236274f11a7eb489c59823eb5","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"," 27%|██▋       | 8002/30000 [2:57:17<8:07:23,  1.33s/it] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-672c8b44e9d2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mminibatch_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mstep_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-08ce613b5e09>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, minibatch, step)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mloss_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mce_d\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_gce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["start_step = 1\n","n_steps = 30001 #hparams['num_training_steps']\n","checkpoint_freq = 1000\n","train_losses = {}\n","\n","for seed in random_seeds:\n","    print('Training Seed:' , seed)\n","    algorithm = LfF(num_classes=NUM_CLASSES, num_attributes=NUM_ATTRIBUTES, hparams=hparams)\n","    algorithm.to(device)\n","    ### Matching the Keys ###\n","    sd_init = torch.load(init_state_dict_path(seed))\n","    sd_init_matched = {f'pred_model.{key}' :sd_init[key]  for key in sd_init.keys()}\n","    sd_algorithm = algorithm.state_dict()\n","    for key in sd_init_matched:\n","        sd_algorithm[key] = sd_init_matched[key]\n","    algorithm.load_state_dict(sd_algorithm)\n","    #########################\n","\n","    train_losses[seed] = []\n","\n","    train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                        weights=train_weights,\n","                                        batch_size=batch_size,\n","                                        num_workers=1)\n","    train_minibatches_iterator = iter(train_loader)\n","\n","    for step in tqdm.tqdm(range(start_step, n_steps)):\n","        ### Training Step ###\n","        i, x, y, a = next(train_minibatches_iterator)\n","        minibatch_device = (i, x.to(device), y.to(device), a.to(device))\n","        algorithm.train()\n","        step_vals = algorithm.update(minibatch_device, step)\n","        train_losses[seed].append(step_vals['loss'])\n","\n","        ### Evaluation ###\n","        if (step % checkpoint_freq == 0) or (step == n_steps - 1):\n","            epoch = int(step / checkpoint_freq)\n","            algorithm_state_dict = algorithm.state_dict()\n","            algorithm_state_dict_PATH = state_dict_PATH + f'seed{seed}/sd_epoch{epoch}.pth'\n","            torch.save(algorithm_state_dict, algorithm_state_dict_PATH)\n","\n","    loss_PATH = state_dict_PATH + f'Loss_{algorithm_name}_{seed}.pth'\n","    torch.save(train_losses, loss_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQw_tuYzW2kn"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP7xbLulahLWIL9+H1IpwFV","gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05bd18d236274f11a7eb489c59823eb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6dc40b9bbed54b198d75744b10698a68","IPY_MODEL_852790756f464e719ebd8fa6b25ec5a5","IPY_MODEL_c29fe13b3f1b48fa8b955d2f9f3ecee0"],"layout":"IPY_MODEL_7dca342ad93a4afdbd0e9ce1e92b251d"}},"0babc266d395446b8e3a385a99b25272":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c3803a64a3d45c4bf90e1a6f3550b4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27f26a3740fe4ef3934bfbf0a36bfa3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51aa5a90bbe0437ba37d88322a3fd809":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc40b9bbed54b198d75744b10698a68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c09bea900fc04f5ca9c5fbe6bf6b6e13","placeholder":"​","style":"IPY_MODEL_0babc266d395446b8e3a385a99b25272","value":"model.safetensors: 100%"}},"7dca342ad93a4afdbd0e9ce1e92b251d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"852790756f464e719ebd8fa6b25ec5a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51aa5a90bbe0437ba37d88322a3fd809","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27f26a3740fe4ef3934bfbf0a36bfa3b","value":440449768}},"c09bea900fc04f5ca9c5fbe6bf6b6e13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c29fe13b3f1b48fa8b955d2f9f3ecee0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c3803a64a3d45c4bf90e1a6f3550b4b","placeholder":"​","style":"IPY_MODEL_e2a93d8a445e4461a17c550b10f84f97","value":" 440M/440M [00:05&lt;00:00, 83.9MB/s]"}},"e2a93d8a445e4461a17c550b10f84f97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
