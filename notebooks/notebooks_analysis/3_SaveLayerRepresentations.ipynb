{"cells":[{"cell_type":"markdown","metadata":{"id":"03FcolRXu3D-"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6363,"status":"ok","timestamp":1716236504203,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"UUFluepQu5S8","outputId":"1788bb7b-9964-47ea-b92b-8b67b3d6a285"},"outputs":[],"source":["!pip install einops datasets jaxtyping better_abc fancy_einsum wandb netcal"]},{"cell_type":"markdown","metadata":{"id":"8trqjnsHBqft"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6433,"status":"ok","timestamp":1716236510633,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JT1BvkRYBuFX","outputId":"68d5111c-21f2-4ad3-d6bc-fb04c15cd965"},"outputs":[],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3287,"status":"ok","timestamp":1716236513919,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bW4KeHLnDSuu"},"outputs":[],"source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM\n","from reprshift.models.hparams import hparams_f\n","from reprshift.dataset.datasets import MultiNLI, CivilComments\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader\n","\n","from reprshift.models.model_param_maps import ERM_to_HookedEncoder, load_focal, load_groupdro, load_jtt, load_lff\n","from reprshift.models.HookedEncoderConfig import bert_config\n","\n","from transformer_lens2 import HookedEncoder, HookedTransformerConfig\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"_kycbc_ci9qU"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23729,"status":"ok","timestamp":1716236750898,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"qa7s8EU3i-2g","outputId":"47a54dfe-d49b-4fa3-caba-d6459a1f0232"},"outputs":[],"source":["DATASET = 'MultiNLI'  # 'CivilComments' , 'MultiNLI'\n","\n","if DATASET == 'MultiNLI':\n","    NUM_CLASSES = 3\n","    NUM_ATTRIBUTES = 2\n","    # train_dataset = MultiNLI(data_path, 'tr', hparams=hparams_f('ERM'))\n","    # val_dataset = MultiNLI(data_path, 'va', hparams=hparams_f('ERM'))\n","    te_dataset = MultiNLI(data_path, 'te', hparams=hparams_f('ERM'))\n","    models_path = path_to_root + '/models/models_mnli'\n","    representations_path = path_to_root + '/representations/representations_mnli'\n","    print(DATASET)\n","elif DATASET  == 'CivilComments':\n","    NUM_CLASSES = 2\n","    NUM_ATTRIBUTES = 8\n","    # train_dataset = CivilComments(data_path, 'tr', hparams=hparams_f('ERM'), granularity=\"fine\")\n","    # val_dataset = CivilComments(data_path, 'va', hparams=hparams_f('ERM'))\n","    te_dataset = CivilComments(data_path, 'te', hparams=hparams_f('ERM'))\n","    models_path = path_to_root + '/models/models_civilcomments'\n","    representations_path = path_to_root + '/representations/representations_civilcomments'\n","    print(DATASET)\n","else:\n","    print('Dataset Not Implemented')"]},{"cell_type":"markdown","metadata":{"id":"YzYFunhMk3As"},"source":["# Save CLS Repr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4006362,"status":"ok","timestamp":1716240764428,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"PIkrwjtVn8s1","outputId":"06418028-42ad-46f5-ee15-86d258ce48f6"},"outputs":[],"source":["for SEED in [0,1,2]:\n","    valmetrics = torch.load(path_to_root + f'/results/ValidationMetrics/clean_val_results.pth')\n","    CURRENT_BEST_EPOCH = valmetrics[DATASET][SEED]['WGA Selection']\n","\n","    ### MODELS ###\n","    MODELS  = {'pretrained': {'path': models_path + '/00_randominit/',  'load_f': lambda x: x, 'epoch':0,},\n","              'erm': {'path': models_path + '/01_erm/',  'load_f': lambda x: x, 'epoch':CURRENT_BEST_EPOCH['erm'],},\n","              'groupdro': {'path': models_path + '/03_groupdro/',  'load_f': load_groupdro, 'epoch':CURRENT_BEST_EPOCH['groupdro'],},\n","              'jtt': {'path': models_path + '/06_jtt/',  'load_f': load_jtt, 'epoch':CURRENT_BEST_EPOCH['jtt'],},\n","              'lff': {'path': models_path + '/07_lff/',  'load_f': load_lff, 'epoch':CURRENT_BEST_EPOCH['lff'],},\n","              'focal': {'path': models_path + '/15_focal/',  'load_f': lambda x: x, 'epoch':CURRENT_BEST_EPOCH['focal'],},}\n","\n","    def load_and_init(algorithm_name, seed):\n","        state_dict_PATH = MODELS[algorithm_name]['path']\n","        load_f =  MODELS[algorithm_name]['load_f']\n","        epoch = MODELS[algorithm_name]['epoch']\n","        algorithm_state_dict_PATH = state_dict_PATH + f'seed{seed}/sd_epoch{epoch}.pth'\n","        sd = load_f(torch.load(algorithm_state_dict_PATH))\n","        ### Initialize ERM Model ###\n","        # hparams = hparams_f('ERM')\n","        # algorithm = ERM(num_classes=NUM_CLASSES, num_attributes=NUM_ATTRIBUTES, hparams=hparams)\n","        # algorithm.load_state_dict(sd)\n","        ### Load ERM Model ###\n","        bert = HookedEncoder(HookedTransformerConfig(**bert_config(NUM_CLASSES)))\n","        bert.load_state_dict(ERM_to_HookedEncoder(sd, bert.state_dict()))\n","        return bert\n","\n","    ######################################\n","    algorithm_names = ['pretrained', 'erm', 'groupdro', 'jtt', 'lff', 'focal']\n","    if DATASET == 'CivilComments':\n","        per_group_repr = 225 #225\n","    if DATASET == 'MultiNLI':\n","        per_group_repr = 600 #600\n","    algorithms = {algorithm_name: load_and_init(algorithm_name, SEED).cuda().eval() for algorithm_name in algorithm_names}\n","\n","\n","    ######################################\n","    ### Add Randomly Initialized Model ###\n","    ######################################\n","    cfg = bert_config(NUM_CLASSES)\n","    cfg['init_mode'] = 'xavier_normal'\n","    bert_random = HookedEncoder(HookedTransformerConfig(**bert_config(NUM_CLASSES)))\n","    algorithms['randominit'] = bert_random\n","    algorithm_names = ['randominit', 'pretrained', 'erm', 'groupdro', 'focal', 'jtt', 'lff', ]\n","    # Function to initialize model weights with Xavier normal initialization\n","    def initialize_weights(model):\n","        for name, param in model.named_parameters():\n","            torch.nn.init.normal_(param.data, mean=0.0, std=0.02)\n","    # Apply the initialization function to the transformer model\n","    initialize_weights(bert_random)\n","\n","\n","    #########################################################\n","    ### Do the Forward Passes and Get CLS Representations ###\n","    #########################################################\n","    unique_y = [i for i in range(NUM_CLASSES)]\n","    unique_a = [i for i in range(NUM_ATTRIBUTES)]\n","\n","    REPRS = {}\n","    LOGITS = {}\n","    for algorithm_name in algorithm_names:\n","        LOGITS[algorithm_name] = {f'y{y_idx}':{f'a{a_idx}':[] for a_idx in unique_a} for y_idx in unique_y}\n","        REPRS[algorithm_name] = {f'layer{i}' : {f'y{y_idx}':{f'a{a_idx}':[] for a_idx in unique_a}  for y_idx in unique_y} for i in range(12)}\n","\n","    for Y_CURR in unique_y:\n","        for A_CURR in unique_a:\n","            print(f'y{Y_CURR}', f'a{A_CURR}')\n","            val_loader = FastDataLoader(  dataset=te_dataset,\n","                                  batch_size=32,\n","                                  num_workers=1,\n","                                  )\n","            train_minibatches_iterator = iter(val_loader)\n","\n","            for step in tqdm.tqdm(range(len(val_loader))):\n","                total_group_members = np.sum([batch.shape[0] for batch in LOGITS['erm'][f'y{Y_CURR}'][f'a{A_CURR}']])\n","                if total_group_members > per_group_repr:\n","                    break\n","                i, x, y, a = next(train_minibatches_iterator)\n","\n","                A_MASK = (a == A_CURR)\n","                Y_MASK = (y == Y_CURR)\n","                MASK = A_MASK & Y_MASK\n","                x = x[MASK]\n","                input_ids = x[:,:,0].cuda()\n","                one_zero_attention_mask = x[:,:,1].cuda()\n","                token_type_ids = x[:,:,2].cuda()\n","\n","                for algorithm_name in algorithm_names:\n","                    bert = algorithms[algorithm_name]\n","                    with torch.no_grad():\n","                        logits, cache = bert.run_with_cache(input_ids, one_zero_attention_mask=one_zero_attention_mask, token_type_ids=token_type_ids)\n","                        LOGITS[algorithm_name][f'y{Y_CURR}'][f'a{A_CURR}'].append(logits.detach().cpu())\n","                        for layer_idx in range(12):\n","                            REPRS[algorithm_name][f'layer{layer_idx}'][f'y{Y_CURR}'][f'a{A_CURR}'].append(cache[f'blocks.{layer_idx}.hook_normalized_resid_post'][:,0,:].detach().cpu())\n","                    del logits, cache\n","                    torch.cuda.empty_cache()\n","\n","            for algorithm_name in algorithm_names:\n","                LOGITS[algorithm_name][f'y{Y_CURR}'][f'a{A_CURR}'] = torch.cat(LOGITS[algorithm_name][f'y{Y_CURR}'][f'a{A_CURR}'])[:per_group_repr]\n","                for layer_idx in range(12):\n","                    REPRS[algorithm_name][f'layer{layer_idx}'][f'y{Y_CURR}'][f'a{A_CURR}'] =  torch.cat(REPRS[algorithm_name][f'layer{layer_idx}'][f'y{Y_CURR}'][f'a{A_CURR}'])[:per_group_repr]\n","\n","    ######################################\n","    ### Save Random Matrix of Same Size ##\n","    ######################################\n","    algorithm_key = 'random'\n","    REPRS[algorithm_key] = {}\n","    for layer_key in tqdm.tqdm(REPRS['erm'].keys()):\n","        REPRS[algorithm_key][layer_key] = {}\n","        for y_key in REPRS['erm'][layer_key].keys():\n","            REPRS[algorithm_key][layer_key][y_key] = {}\n","            for a_key in REPRS['erm'][layer_key][y_key].keys():\n","                REPRS[algorithm_key][layer_key][y_key][a_key] = torch.rand_like(REPRS['erm'][layer_key][y_key][a_key])\n","\n","    ###############################\n","    ### Save Everything to Drive ##\n","    ###############################\n","    torch.save(LOGITS, f'{representations_path}/seed{SEED}'+'_logits')\n","    torch.save(REPRS, f'{representations_path}/seed{SEED}'+'_reprs')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOHpBU4gbTkECYH8Kjra+tM","collapsed_sections":["03FcolRXu3D-","8trqjnsHBqft"],"gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
