{"cells":[{"cell_type":"markdown","metadata":{"id":"03FcolRXu3D-"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6396,"status":"ok","timestamp":1716252637012,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"UUFluepQu5S8","outputId":"04e085a1-816f-47f7-fb35-ad552a2e5929"},"outputs":[],"source":["!pip install einops datasets jaxtyping better_abc fancy_einsum wandb netcal"]},{"cell_type":"markdown","metadata":{"id":"8trqjnsHBqft"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13341,"status":"ok","timestamp":1716256796159,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JT1BvkRYBuFX","outputId":"92eea57f-0963-4466-876a-492e1261cc80"},"outputs":[],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":8383,"status":"error","timestamp":1716256804541,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bW4KeHLnDSuu","outputId":"9f249739-c7c5-4102-c7ee-7494b531b2dc"},"outputs":[],"source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM\n","from reprshift.models.hparams import hparams_f\n","from reprshift.dataset.datasets import MultiNLI, CivilComments\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader\n","\n","from reprshift.models.model_param_maps import ERM_to_HookedEncoder, load_focal, load_groupdro, load_jtt, load_lff\n","from reprshift.models.HookedEncoderConfig import bert_config\n","\n","from transformer_lens2 import HookedEncoder, HookedTransformerConfig\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"_kycbc_ci9qU"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1716253622194,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"qa7s8EU3i-2g","outputId":"be1a5fe2-1a26-4b2e-c722-5b8aaf6a600f"},"outputs":[],"source":["SEED = 0\n","DATASET = 'CivilComments'  # 'CivilComments' , 'MultiNLI'\n","\n","if DATASET == 'MultiNLI':\n","    NUM_CLASSES = 3\n","    NUM_ATTRIBUTES = 2\n","    # train_dataset = MultiNLI(data_path, 'tr', hparams)\n","    # val_dataset = MultiNLI(data_path, 'va', hparams=hparams_f('ERM'))\n","    # te_dataset = MultiNLI(data_path, 'te', hparams=hparams_f('ERM'))\n","    models_path = path_to_root + '/models/models_mnli'\n","    representations_path = path_to_root + '/representations/representations_mnli'\n","    print(DATASET)\n","elif DATASET  == 'CivilComments':\n","    NUM_CLASSES = 2\n","    NUM_ATTRIBUTES = 8\n","    # train_dataset = CivilComments(data_path, 'tr', hparams, granularity=\"fine\")\n","    # val_dataset = CivilComments(data_path, 'va', hparams=hparams_f('ERM'))\n","    # te_dataset = CivilComments(data_path, 'te', hparams=hparams_f('ERM'))\n","    models_path = path_to_root + '/models/models_civilcomments'\n","    representations_path = path_to_root + '/representations/representations_civilcomments'\n","    print(DATASET)\n","else:\n","    print('Dataset Not Implemented')"]},{"cell_type":"markdown","metadata":{"id":"uJEOd97WDL1A"},"source":["# Probe Representations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":846,"status":"ok","timestamp":1716253623537,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"OqmTOEPNDLCf","outputId":"5d9b5fbc-3a42-4421-90fe-1b3c855eb851"},"outputs":[],"source":["algorithm_names =  ['random', 'randominit', 'pretrained', 'erm', 'groupdro', 'focal', 'jtt', 'lff', ]\n","REPRS = torch.load(f'{representations_path}/seed{SEED}'+'_reprs')\n","REPRS.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716253623537,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"IoZZUc7MlTDV","outputId":"41a255da-ebe0-419d-b600-ed8460026c85"},"outputs":[],"source":["PER_GROUP_REPR = int(3600 / (NUM_CLASSES * NUM_ATTRIBUTES))\n","PER_GROUP_REPR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716253623537,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"UVi0l7PQDUbg","outputId":"70cebba6-3644-4725-f474-a2145612c97e"},"outputs":[],"source":["CAT_REPRS = {}\n","\n","## Add the rest\n","for algorithm_key in algorithm_names:\n","    CAT_REPRS[algorithm_key] = {}\n","    for layer_key in tqdm.tqdm(REPRS[algorithm_key].keys()):\n","        CAT_REPRS[algorithm_key][layer_key] = []\n","        for y_key in REPRS[algorithm_key][layer_key].keys():\n","            for a_key in REPRS[algorithm_key][layer_key][y_key].keys():\n","                CAT_REPRS[algorithm_key][layer_key].append(REPRS[algorithm_key][layer_key][y_key][a_key])\n","        CAT_REPRS[algorithm_key][layer_key] = torch.cat(CAT_REPRS[algorithm_key][layer_key])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUy1FJPJD3nQ"},"outputs":[],"source":["CAT_LABEL_A = []\n","CAT_LABEL_Y = []\n","\n","for y_idx, y_key in enumerate(REPRS[algorithm_key][layer_key].keys()):\n","    for a_idx, a_key in enumerate(REPRS[algorithm_key][layer_key][y_key].keys()):\n","        CAT_LABEL_A += [a_idx] * PER_GROUP_REPR\n","        CAT_LABEL_Y += [y_idx] * PER_GROUP_REPR\n","\n","CAT_LABEL_A = torch.tensor(CAT_LABEL_A)#[:CAT_REPRS['erm']['layer0'].shape[0]]\n","CAT_LABEL_Y = torch.tensor(CAT_LABEL_Y)#[:CAT_REPRS['erm']['layer0'].shape[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716253624149,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"1nGwEUznqMK6","outputId":"a5165d06-f301-4c9c-ac2b-a119a2dba8c9"},"outputs":[],"source":["CAT_LABEL_A.shape, CAT_LABEL_Y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57deGOM5JX3C"},"outputs":[],"source":["# algorithm_name = 'random'\n","# layer_no = 'layer10'\n","# X = CAT_REPRS[algorithm_name][layer_no]\n","# Y = CAT_LABEL_A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIiUhNdNJo-X"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score\n","\n","\n","# Probes\n","class OneLayerMLP(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(OneLayerMLP, self).__init__()\n","        self.layer1 = nn.Linear(input_dim, output_dim)\n","\n","    def forward(self, x):\n","        return self.layer1(x)\n","\n","class TwoLayerMLP(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(TwoLayerMLP, self).__init__()\n","        self.layer1 = nn.Linear(input_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.layer2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.relu(x)\n","        x = self.layer2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"siAXauklLbix"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# compact function for probing the representations\n","def ProbeReprs(X, Y):\n","    X_train, X_temp, Y_train, Y_temp = train_test_split(X.detach().clone(), Y.detach().clone(), test_size=0.3, random_state=0, shuffle=True)\n","    X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=0, shuffle=True)\n","\n","    # scale the data - standard scaler\n","    # scaler = StandardScaler()\n","    # X_train = torch.tensor(scaler.fit_transform(X_train))\n","    # X_val = torch.tensor(scaler.transform(X_val))\n","    # X_test = scaler.transform(X_test)\n","\n","    input_dim = X_train.shape[1]\n","    output_dim = len(np.unique(np.array(Y)))\n","    hidden_dim = 128\n","    learning_rate = 0.001\n","    num_epochs = 100\n","\n","    one_layer_model = OneLayerMLP(input_dim, output_dim)\n","    two_layer_model = TwoLayerMLP(input_dim, hidden_dim, output_dim)\n","    optimizer_one_layer = optim.Adam(one_layer_model.parameters(), lr=learning_rate)\n","    optimizer_two_layer = optim.Adam(two_layer_model.parameters(), lr=learning_rate)\n","    loss_function = nn.CrossEntropyLoss()\n","\n","    Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n","    Y_val_tensor = torch.tensor(Y_val, dtype=torch.long)\n","    def train_model(model, optimizer, X_train, Y_train, X_val, Y_val):\n","        best_val_acc = 0\n","        final_best_model = None\n","\n","        for epoch in range(num_epochs):\n","            # do a training step full-batch\n","            model.train()\n","            outputs = model(X_train)\n","            loss = loss_function(outputs, Y_train)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            model.eval()\n","            with torch.no_grad():\n","                # compute validation acc\n","                val_outputs = model(X_val)\n","                _, predicted = torch.max(val_outputs.data, 1)\n","\n","                val_acc = accuracy_score(Y_val, predicted)\n","                if val_acc > best_val_acc:\n","                    best_val_acc = val_acc\n","                    final_best_model = model.state_dict()\n","\n","        return final_best_model, best_val_acc\n","\n","    # train one  layer model\n","    best_one_layer_model, best_one_layer_val_acc = train_model(one_layer_model, optimizer_one_layer, X_train_tensor, Y_train_tensor, X_val_tensor, Y_val_tensor)\n","    one_layer_model.load_state_dict(best_one_layer_model)\n","    # train two layer model\n","    best_two_layer_model, best_two_layer_val_acc = train_model(two_layer_model, optimizer_two_layer, X_train_tensor, Y_train_tensor, X_val_tensor, Y_val_tensor)\n","    two_layer_model.load_state_dict(best_two_layer_model)\n","\n","    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","    Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n","    def evaluate_model(model, X_test, Y_test):\n","        model.eval()  \n","        with torch.no_grad():\n","            test_outputs = model(X_test)\n","            _, predicted = torch.max(test_outputs.data, 1)\n","            test_acc = accuracy_score(Y_test, predicted)\n","            return test_acc\n","\n","    return {'one layer': evaluate_model(one_layer_model, X_test_tensor, Y_test_tensor), 'two layer': evaluate_model(two_layer_model, X_test_tensor, Y_test_tensor)}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148579,"status":"ok","timestamp":1716253772724,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"0dQEai2NMEPb","outputId":"ba0d8d85-8387-4394-eabd-132c0df9e4ba"},"outputs":[],"source":["Y_PROBE_DICT1 = pd.DataFrame(index=CAT_REPRS['erm'].keys(), columns=CAT_REPRS.keys())\n","Y_PROBE_DICT2 = pd.DataFrame(index=CAT_REPRS['erm'].keys(), columns=CAT_REPRS.keys())\n","A_PROBE_DICT1 = pd.DataFrame(index=CAT_REPRS['erm'].keys(), columns=CAT_REPRS.keys())\n","A_PROBE_DICT2 = pd.DataFrame(index=CAT_REPRS['erm'].keys(), columns=CAT_REPRS.keys())\n","\n","for algorithm_name in CAT_REPRS.keys():\n","    print(algorithm_name)\n","    for layer_no in tqdm.tqdm(CAT_REPRS['erm'].keys()):\n","        PY = ProbeReprs(CAT_REPRS[algorithm_name][layer_no], CAT_LABEL_Y)\n","        Y_PROBE_DICT1[algorithm_name].loc[layer_no] = PY['one layer']\n","        Y_PROBE_DICT2[algorithm_name].loc[layer_no] = PY['two layer']\n","        PA = ProbeReprs(CAT_REPRS[algorithm_name][layer_no], CAT_LABEL_A)\n","        A_PROBE_DICT1[algorithm_name].loc[layer_no] = PA['one layer']\n","        A_PROBE_DICT2[algorithm_name].loc[layer_no] = PA['two layer']\n","\n","PROBES = pd.concat({'A1L': A_PROBE_DICT1,'A2L':A_PROBE_DICT2, 'Y1L':Y_PROBE_DICT1,'Y2L':Y_PROBE_DICT2,})\n","PROBES.to_csv(path_to_root + f'/results/Probe/{DATASET}_seed{SEED}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXGFX4ouYnQy"},"outputs":[],"source":["import pandas as pd\n","\n","# PROBE_PATH = path_to_root + f'/results/Probe/{DATASET}_seed{SEED}'\n","# df = pd.read_csv(PROBE_PATH, index_col=['Unnamed: 0','Unnamed: 1' ])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716253772725,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"wNXwVl71Ywe5","outputId":"24c8845d-e262-4a96-8d85-d4e9b24c5de8"},"outputs":[],"source":["df.round(3)*100"]},{"cell_type":"markdown","metadata":{"id":"AAL0Vdkt5I9a"},"source":["# Figures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilarUEhB5KFt"},"outputs":[],"source":["### Table ###\n","\n","# Columns: Algorithms\n","# Rows: Layers\n","# Cells: Probe Accuracy\n","\n","# Logistic Regression Probe\n","# Minimum Description Length Probe\n","\n","PROBE_PATH =\n","df = pd.read_csv(path_to_root + f'/results/Probe/{DATASET}_seed{SEED}', index_col=['Unnamed: 0','Unnamed: 1' ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJtyGzAOtNoN"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np\n","\n","DATASET = 'CivilComments' # ['MultiNLI', 'CivilComments']\n","SEED = 0\n","ProbeTables = []\n","\n","for SEED in [0,1,2]:\n","    df = pd.read_csv(path_to_root + f'/results/Probe/{DATASET}_seed{SEED}', index_col=['Unnamed: 0','Unnamed: 1' ])\n","    ProbeTables.append(df * 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRACKLiStThn"},"outputs":[],"source":["### Test Table ###\n","dfs = ProbeTables\n","# dfs = [pd.DataFrame(TestTables[i].drop('Overall').mean()) for i in range(2)] # To Calculate average accuracy\n","stacked_dfs = np.stack(dfs)\n","df_mean_values = np.mean(stacked_dfs, axis=0)\n","df_std_values = np.std(stacked_dfs, axis=0)\n","df_mean = pd.DataFrame(df_mean_values, columns=dfs[0].columns, index=dfs[0].index)\n","df_std = pd.DataFrame(df_std_values, columns=dfs[0].columns, index=dfs[0].index)\n","column_names = [\"Random\", \"Random Init\", \"Pretrained\", \"ERM\", \"GroupDRO\", \"Focal\", \"JTT\", \"LFF\"]\n","df_mean.columns = column_names\n","df_std.columns = column_names"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOr6JP4ljyz7Qy+6rp/AxH4","collapsed_sections":["03FcolRXu3D-","8trqjnsHBqft"],"machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
