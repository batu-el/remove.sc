{"cells":[{"cell_type":"markdown","metadata":{"id":"03FcolRXu3D-"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65345,"status":"ok","timestamp":1716406074619,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"UUFluepQu5S8","outputId":"b4ab2f2e-6177-4df7-fb48-45302b90ec7c"},"outputs":[],"source":["!pip install einops datasets jaxtyping better_abc fancy_einsum wandb netcal"]},{"cell_type":"markdown","metadata":{"id":"8trqjnsHBqft"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21803,"status":"ok","timestamp":1716406096418,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JT1BvkRYBuFX","outputId":"4d28aa77-f239-4231-ae2e-6178a8bd9dfc"},"outputs":[],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31021,"status":"ok","timestamp":1716406127430,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bW4KeHLnDSuu"},"outputs":[],"source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM\n","from reprshift.models.hparams import hparams_f\n","from reprshift.dataset.datasets import MultiNLI, CivilComments\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader\n","\n","from reprshift.models.model_param_maps import ERM_to_HookedEncoder, load_focal, load_groupdro, load_jtt, load_lff\n","from reprshift.models.HookedEncoderConfig import bert_config\n","\n","from transformer_lens2 import HookedEncoder, HookedTransformerConfig\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"_kycbc_ci9qU"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56806,"status":"ok","timestamp":1716411280041,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"qa7s8EU3i-2g","outputId":"2c28906c-ecd9-4dfb-affc-0280591d9243"},"outputs":[],"source":["DATASET = 'MultiNLI'  # 'CivilComments' , 'MultiNLI'\n","SEED = 1\n","\n","if DATASET == 'MultiNLI':\n","    NUM_CLASSES = 3\n","    NUM_ATTRIBUTES = 2\n","    # train_dataset = MultiNLI(data_path, 'tr',  hparams=hparams_f('ERM'))\n","    val_dataset = MultiNLI(data_path, 'va', hparams=hparams_f('ERM'))\n","    te_dataset = MultiNLI(data_path, 'te', hparams=hparams_f('ERM'))\n","    models_path = path_to_root + '/models/models_mnli'\n","    representations_path = path_to_root + '/representations/representations_mnli'\n","    print(DATASET)\n","elif DATASET  == 'CivilComments':\n","    NUM_CLASSES = 2\n","    NUM_ATTRIBUTES = 8\n","    # train_dataset = CivilComments(data_path, 'tr',  hparams=hparams_f('ERM'), granularity=\"fine\")\n","    val_dataset = CivilComments(data_path, 'va', hparams=hparams_f('ERM'))\n","    # te_dataset = CivilComments(data_path, 'te', hparams=hparams_f('ERM'))\n","    models_path = path_to_root + '/models/models_civilcomments'\n","    representations_path = path_to_root + '/representations/representations_civilcomments'\n","    print(DATASET)\n","else:\n","    print('Dataset Not Implemented')"]},{"cell_type":"markdown","metadata":{"id":"YzYFunhMk3As"},"source":["# Models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1716411280041,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"iOJLm_8wglnI"},"outputs":[],"source":["valmetrics = torch.load(path_to_root + f'/results/ValidationMetrics/clean_val_results.pth')\n","CURRENT_BEST_EPOCH = valmetrics[DATASET][SEED]['A Selection']\n","### MODELS ###\n","MODELS  = {'pretrained': {'path': models_path + '/00_randominit/',  'load_f': lambda x: x, 'epoch':0,},\n","          'erm': {'path': models_path + '/01_erm/',  'load_f': lambda x: x, 'epoch':CURRENT_BEST_EPOCH['erm'],},\n","          'groupdro': {'path': models_path + '/03_groupdro/',  'load_f': load_groupdro, 'epoch':CURRENT_BEST_EPOCH['groupdro'],},\n","          'jtt': {'path': models_path + '/06_jtt/',  'load_f': load_jtt, 'epoch':CURRENT_BEST_EPOCH['jtt'],},\n","          'lff': {'path': models_path + '/07_lff/',  'load_f': load_lff, 'epoch':CURRENT_BEST_EPOCH['lff'],},\n","          'focal': {'path': models_path + '/15_focal/',  'load_f': lambda x: x, 'epoch':CURRENT_BEST_EPOCH['focal'],},}\n","\n","def load_and_init(algorithm_name, seed):\n","    state_dict_PATH = MODELS[algorithm_name]['path']\n","    load_f =  MODELS[algorithm_name]['load_f']\n","    epoch = MODELS[algorithm_name]['epoch']\n","    algorithm_state_dict_PATH = state_dict_PATH + f'seed{seed}/sd_epoch{epoch}.pth'\n","    sd = load_f(torch.load(algorithm_state_dict_PATH))\n","    ### Initialize ERM Model ###\n","    # hparams = hparams_f('ERM')\n","    # algorithm = ERM(num_classes=NUM_CLASSES, num_attributes=NUM_ATTRIBUTES, hparams=hparams)\n","    # algorithm.load_state_dict(sd)\n","    ### Load ERM Model ###\n","    bert = HookedEncoder(HookedTransformerConfig(**bert_config(NUM_CLASSES)))\n","    bert.load_state_dict(ERM_to_HookedEncoder(sd, bert.state_dict()))\n","    return bert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":843,"status":"ok","timestamp":1716411280871,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"toDNhDNb8XnW","outputId":"876b61a9-4990-4c7f-9820-e42aee215807"},"outputs":[],"source":["bert = load_and_init('erm', SEED).cuda().eval()\n","# Set requires_grad to False for all parameters of BERT\n","for param in bert.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716411280871,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"ipa_RnwVJv6s","outputId":"dc7cc26b-f3ee-42b1-dd20-1999217be1df"},"outputs":[],"source":["CURRENT_BEST_EPOCH"]},{"cell_type":"markdown","metadata":{"id":"NdFsLSJp9Mbj"},"source":["# Cache Representations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1716411281238,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"frq-DOYd87h_","outputId":"b2d1db41-40f4-4da9-f9f2-b3278f331f56"},"outputs":[],"source":["if DATASET == 'CivilComments':\n","    per_group_repr = 150\n","if DATASET == 'MultiNLI':\n","    per_group_repr = 600\n","\n","unique_y = [i for i in range(NUM_CLASSES)]\n","unique_a = [i for i in range(NUM_ATTRIBUTES)]\n","y_s = [f'y{i}' for i in range(NUM_CLASSES)]\n","a_s = [f'a{i}' for i in range(NUM_ATTRIBUTES)]\n","\n","REPR_KEYS = ['blocks.11.ln1.hook_normalized', 'blocks.11.mlp.hook_post' , 'blocks.11.hook_mlp_out', 'blocks.11.ln2.hook_normalized']\n","REPRS = {repr_key: {f'y{y_idx}':{f'a{a_idx}':[] for a_idx in unique_a}  for y_idx in unique_y} for repr_key in REPR_KEYS}\n","LOGITS = {f'y{y_idx}':{f'a{a_idx}':[] for a_idx in unique_a} for y_idx in unique_y}\n","LOGITS, REPRS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716411281239,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"4YyycGAnOx2W"},"outputs":[],"source":["SPLIT = 'va'  # 'tr', 'va', 'te'\n","\n","# if SPLIT == 'tr':\n","#     dataset = train_dataset\n","# elif SPLIT == 'va':\n","#     dataset = val_dataset\n","# elif SPLIT == 'te':\n","#     dataset = te_dataset\n","# else:\n","#     print('Split Unavailable')\n","\n","# for Y_CURR in unique_y:\n","#     for A_CURR in unique_a:\n","#         print(f'y{Y_CURR}', f'a{A_CURR}')\n","#         val_loader = FastDataLoader(  dataset=dataset,\n","#                               batch_size=32,\n","#                               num_workers=1,\n","#                               )\n","#         train_minibatches_iterator = iter(val_loader)\n","\n","#         for step in tqdm.tqdm(range(len(val_loader))):\n","#             total_group_members = np.sum([batch.shape[0] for batch in LOGITS[f'y{Y_CURR}'][f'a{A_CURR}']])\n","#             if total_group_members > per_group_repr:\n","#                 break\n","#             i, x, y, a = next(train_minibatches_iterator)\n","\n","#             A_MASK = (a == A_CURR)\n","#             Y_MASK = (y == Y_CURR)\n","#             MASK = A_MASK & Y_MASK\n","#             x = x[MASK]\n","#             input_ids = x[:,:,0].cuda()\n","#             one_zero_attention_mask = x[:,:,1].cuda()\n","#             token_type_ids = x[:,:,2].cuda()\n","\n","#             with torch.no_grad():\n","#                 logits, cache = bert.run_with_cache(input_ids, one_zero_attention_mask=one_zero_attention_mask, token_type_ids=token_type_ids)\n","#                 LOGITS[f'y{Y_CURR}'][f'a{A_CURR}'].append(logits[:,0,:].detach().cpu())\n","#                 for repr_key in REPR_KEYS:\n","#                     REPRS[repr_key][f'y{Y_CURR}'][f'a{A_CURR}'].append(cache[repr_key][:,0,:].detach().cpu())\n","#             del logits, cache\n","#             torch.cuda.empty_cache()\n","#         LOGITS[f'y{Y_CURR}'][f'a{A_CURR}'] = torch.cat(LOGITS[f'y{Y_CURR}'][f'a{A_CURR}'])[:per_group_repr]\n","#         for repr_key in REPR_KEYS:\n","#             REPRS[repr_key][f'y{Y_CURR}'][f'a{A_CURR}'] =  torch.cat(REPRS[repr_key][f'y{Y_CURR}'][f'a{A_CURR}'])[:per_group_repr]\n","\n","# torch.save(LOGITS, representations_path + f'/ModelEdit/LOGITS_{SPLIT}_seed{SEED}' )\n","# torch.save(REPRS, representations_path + f'/ModelEdit/REPRS_{SPLIT}_seed{SEED}' )"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1716411281621,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"ASpVboFlK3qb"},"outputs":[],"source":["LOGITS = torch.load(representations_path + f'/ModelEdit/LOGITS_{SPLIT}_seed{SEED}')\n","REPRS  = torch.load(representations_path + f'/ModelEdit/REPRS_{SPLIT}_seed{SEED}' )\n","REPRS_TRAIN  = torch.load(representations_path + f'/ModelEdit/REPRS_tr_seed{SEED}' )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1716411282019,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"sZidHA4JOsIO","outputId":"40bbc3ad-d854-40aa-d338-79f3f475136f"},"outputs":[],"source":["### Sanity Check:  bert.W_out[11] ###\n","mlp_out = lambda x: (x.cuda()  @ bert.W_out[11]) +  bert.b_out[11]\n","mlp_out(REPRS['blocks.11.mlp.hook_post']['y0']['a0']).shape, REPRS['blocks.11.hook_mlp_out']['y0']['a0'].shape\n","REPRS['blocks.11.hook_mlp_out']['y0']['a0'].cuda().round(decimals=4) == mlp_out(REPRS['blocks.11.mlp.hook_post']['y0']['a0']).round(decimals=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716411282020,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"18GOBHXcOxWv","outputId":"97468ac4-0ac5-4977-a618-c72ae6496111"},"outputs":[],"source":["### Sanity Check:  Logit Lens ###\n","def Layer11Norm2(res):\n","    res = bert.blocks[11].ln2(res.unsqueeze(dim=1).cuda())\n","    return res\n","def LogitLens(res):\n","    res = bert.mlm_head(res)\n","    res = bert.unembed(res)\n","    return res\n","def LogitLenswLayer11Norm2(res):\n","    res = bert.blocks[11].ln2(res.unsqueeze(dim=1).cuda())\n","    res = bert.mlm_head(res)\n","    res = bert.unembed(res)\n","    return res[:,0,:]\n","\n","# Implementation with Matrix Multiplication\n","def logit_lens_with_norm(cls_reprs, sd=bert.state_dict()):\n","  cls_reprs = cls_reprs.cuda()\n","  mean = cls_reprs.mean(dim=1, keepdim=True)\n","  std = cls_reprs.std(dim=1, keepdim=True)\n","  cls_reprs = (cls_reprs - mean) / (std)\n","  cls_reprs = (sd['blocks.11.ln2.w'] * cls_reprs) + sd['blocks.11.ln2.b']\n","  out = cls_reprs @ sd['mlm_head.W'].T\n","  out = out + sd['mlm_head.b']\n","  out = torch.tanh(out)\n","  out = out @ sd['unembed.W_U']\n","  out = out + sd['unembed.b_U']\n","  return out\n","\n","resid_post = REPRS['blocks.11.ln1.hook_normalized']['y0']['a0'] + REPRS['blocks.11.hook_mlp_out']['y0']['a0']\n","# Implementation with Matrix Multiplication\n","# logit_lens_with_norm(resid_post)[:,:], LOGITS['y0']['a0']\n","# Implementation with Components\n","LogitLenswLayer11Norm2(resid_post), LOGITS['y0']['a0']"]},{"cell_type":"markdown","metadata":{"id":"Vh5lF2vy9dLa"},"source":["# Step 1: Calculating the Key\n","\n","The key is the representation of the shortcut in the internal representation of the model. In the ROME paper, this is calculated by passing a set of sequences that contain the key through the model and caching the representations. Then, the representations are averaged to calculate the key $k^{*}$.\n","\n","Here, we are aiming to capture the representation of the shortcut. Hence, we pass the data with and without the shortcut through the model and cache the activations. As a key, we use two alternatives:\n","\n","1. The average of the representations from examples with shortcuts.\n","2. The difference between the average of examples with and without shortcut."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716411282020,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"OejLiv6M9gdh","outputId":"62a8c30f-4c58-4b8a-9434-9b64ea9ac4af"},"outputs":[],"source":["### Define Keys ###\n","a0_hook_post = torch.cat([REPRS['blocks.11.mlp.hook_post'][f'y{label_idx}']['a0'] for label_idx in [0,1,2]])\n","a1_hook_post = torch.cat([REPRS['blocks.11.mlp.hook_post'][f'y{label_idx}']['a1'] for label_idx in [0,1,2]])\n","key_mean = a1_hook_post.mean(dim=0)\n","key_diff = a1_hook_post.mean(dim=0) - a0_hook_post.mean(dim=0)\n","print(key_mean.shape, key_diff.shape)\n","### The Key for Shortcut ###\n","k_star = key_mean"]},{"cell_type":"markdown","metadata":{"id":"0QhdDMK49iWj"},"source":["# Step 2: Calculating the Value\n","\n","This is the value that needs to be written on the residual stream in order to decrease the logit of the contradiction class. This can be computed by solving a simple optimization problem:\n","\n","What is the vector that needs to be added to the residual stream so that the logits that correspond to the contradiction class are suppressed?\n","\n","As an additional contraint, we add the requirement that the logits that correspond to non-shortcut examples are not changed."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716411282020,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"WAlNcvLbQwbU","outputId":"080a6dcb-c143-44b7-af46-a9b9a6844017"},"outputs":[],"source":["resid_post = REPRS['blocks.11.ln1.hook_normalized']['y0']['a0'] + REPRS['blocks.11.hook_mlp_out']['y0']['a0']\n","res = LogitLenswLayer11Norm2(resid_post)\n","res, LOGITS['y0']['a0']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716411282020,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"zFwwo0g9rb20"},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","\n","# def LogitLenswLayer11Norm2(res):\n","#     res = bert.blocks[11].ln2(res.unsqueeze(dim=1).cuda())\n","#     res = bert.mlm_head(res)\n","#     res = bert.unembed(res)\n","#     return res[:,0,:]\n","\n","# class Model(nn.Module):\n","#     def __init__(self, d_model):\n","#         super(Model, self).__init__()\n","#         self.param_vector = nn.Parameter(torch.randn(d_model).to(torch.float32))\n","\n","#     def forward(self, x):\n","#         x = x + self.param_vector\n","#         x = LogitLenswLayer11Norm2(x)\n","#         return x\n","\n","# model = Model(768).cuda()\n","# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1)\n","\n","# # Objective 1: Minimize Contradiction Logit\n","# # a0_ln1_hook = torch.cat([REPRS['blocks.11.ln1.hook_normalized'][f'y{label_idx}']['a0'] for label_idx in [0,1,2]]).cuda()\n","# a1_ln1_hook = torch.cat([REPRS['blocks.11.ln1.hook_normalized'][f'y{label_idx}']['a1'] for label_idx in [0,1,2]]).cuda()\n","\n","# # Objective 2: Keep the other Logits Constant\n","# a1_logits = torch.cat([LOGITS[f'y{label_idx}']['a1'] for label_idx in [0,1,2]]).cuda()\n","\n","# losses = []\n","# # Training loop\n","# for _ in tqdm.tqdm(range(100)):\n","#     optimizer.zero_grad()\n","#     # Forward pass\n","#     loss = 0\n","#     output = model(a1_ln1_hook)\n","#     loss = output[:, 0].sum()\n","#     # control_loss = (output[:, :] - a1_logits[:, :]).norm()\n","#     # loss = loss + control_loss\n","#     loss.backward()\n","#     optimizer.step()\n","#     losses.append(loss)\n","#     # print(loss.item())\n","\n","# ### v_star ###\n","# v_star = model.param_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3815,"status":"ok","timestamp":1716411684722,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"1dHB0AvV0tVh","outputId":"fcd7df94-3c26-45b0-8e37-8c7a261b7a53"},"outputs":[],"source":["#############################\n","#############################\n","#### ALTERNATIVE 2 ##########\n","#############################\n","#############################\n","\n","import torch\n","import torch.nn as nn\n","\n","def LogitLenswLayer11Norm2(res):\n","    res = bert.blocks[11].ln2(res.unsqueeze(dim=1).cuda())\n","    res = bert.mlm_head(res)\n","    res = bert.unembed(res)\n","    return res[:,0,:]\n","\n","class Model(nn.Module):\n","    def __init__(self, d_model):\n","        super(Model, self).__init__()\n","        self.param_vector = nn.Parameter(torch.randn(d_model).to(torch.float32))\n","\n","    def forward(self, x):\n","        x = x + self.param_vector\n","        x = LogitLenswLayer11Norm2(x)\n","        return x\n","\n","model = Model(768).cuda()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1)\n","\n","# Objective 1: Minimize Contradiction Logit\n","# a0_ln1_hook = torch.cat([REPRS['blocks.11.ln1.hook_normalized'][f'y{label_idx}']['a0'] for label_idx in [0,1,2]]).cuda()\n","a1_ln1_hook = torch.cat([REPRS['blocks.11.ln1.hook_normalized'][f'y{label_idx}']['a1'] for label_idx in [0,1,2]]).cuda()\n","a0_ln1_hook = torch.cat([REPRS['blocks.11.ln1.hook_normalized'][f'y{label_idx}']['a0'] for label_idx in [0,1,2]]).cuda()\n","\n","# Objective 2: Keep the other Logits Constant\n","a1_logits = torch.cat([LOGITS[f'y{label_idx}']['a1'] for label_idx in [0,1,2]]).cuda()\n","a0_logits = torch.cat([LOGITS[f'y{label_idx}']['a1'] for label_idx in [0,1,2]]).cuda()\n","\n","losses = []\n","\n","LogitShiftFactor = {0:4.1, 1:4.5, 2:4.1}\n","\n","\n","for _ in tqdm.tqdm(range(1000)):\n","    optimizer.zero_grad()\n","    loss = 0\n","    output = model(a1_ln1_hook)\n","    # loss = output[:, 0].sum()\n","    a1_control_loss = (output[:, :] - (a1_logits - torch.tensor([LogitShiftFactor[SEED], 0, 0]).cuda())).norm()\n","\n","    output_a0 = model(a0_ln1_hook)\n","    a0_control_loss = (output_a0[:, :] - a0_logits[:, :]).norm()\n","\n","    loss = a1_control_loss + a0_control_loss\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())\n","\n","v_star = model.param_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"elapsed":438,"status":"ok","timestamp":1716411686269,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bO0p5M9m6n7I","outputId":"f51bfe2a-7367-4a9b-a581-14e01f035c16"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(losses, marker='o', linestyle='-', color='b')\n","\n","plt.title('Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.grid(True)\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1716411688187,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JmlkzC8ylyu_","outputId":"c389ab2e-4084-4d95-b4df-1c696776cfe3"},"outputs":[],"source":["alpha = 1\n","\n","### What does v_star do to the logits?\n","for y_idx in [0,1,2]:\n","    print('#################')\n","    for a_idx in ['a0', 'a1']:\n","        print(f'y{y_idx}', a_idx)\n","        resid_post = REPRS['blocks.11.ln1.hook_normalized'][f'y{y_idx}'][a_idx] + REPRS['blocks.11.hook_mlp_out'][f'y{y_idx}'][a_idx]\n","        prev = LogitLenswLayer11Norm2(resid_post).detach().cpu()\n","        resid_post = REPRS['blocks.11.ln1.hook_normalized'][f'y{y_idx}'][a_idx] + (alpha * torch.stack([v_star for i in range(600)]).cpu())\n","        post = LogitLenswLayer11Norm2(resid_post).detach().cpu()\n","        print('prev mean logit:', prev.mean(dim=0))\n","        print('post mean logit:', post.mean(dim=0))\n","\n","        print('prev accuracy:', (prev.argmax(dim=1) == y_idx).sum() / 600)\n","        print('post accuracy:', (post.argmax(dim=1) == y_idx).sum() / 600)"]},{"cell_type":"markdown","metadata":{"id":"qsUk6Ppn4rzj"},"source":["# Step 3: Rank One Edit"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1716411691446,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"9x_T-ZH64s3_"},"outputs":[],"source":["### K-star: the key input ###\n","K_star = k_star.cuda()\n","### V-star: the value output ###\n","V_star = v_star.cuda()\n","### W: Pre-edit Weight Matrix ###\n","W = bert.W_out[11].detach().cuda().T\n","\n","##############################\n","#### Pre-cached C #############\n","##############################\n","Kcutoff = 999999\n","### K Matrix: Each column is a key ###\n","K_a0 = torch.cat([REPRS['blocks.11.mlp.hook_post'][f'y{label_idx}']['a0'][:Kcutoff] for label_idx in [0,1,2]])\n","K_a1 = torch.cat([REPRS['blocks.11.mlp.hook_post'][f'y{label_idx}']['a1'][:Kcutoff] for label_idx in [0,1,2]])\n","K = torch.cat([K_a0, K_a1])[:, :].T.cuda()\n","### C Matrix: K @ K.T ###\n","C = K @ K.T\n","\n","### Lambda:  Λ = (v∗ −Wk∗)/(C−1k∗)T k∗ ###\n","Lambda_numerator = (V_star - W @ K_star)\n","Lambda_denominator = (C.inverse() @ K_star).T @ K_star\n","Lambda = Lambda_numerator / Lambda_denominator\n","### W_hat ###\n","W.shape, Lambda.shape, C.shape, K_star.shape\n","W_hat = W + (Lambda.unsqueeze(1) @ (C.inverse() @ K_star).unsqueeze(dim=1).T)\n","W_edit = W_hat.T"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1716411693197,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"kW023H295Sc3","outputId":"b052390a-db55-40a8-b4ba-16756864d482"},"outputs":[],"source":["import copy\n","bert_updated = copy.deepcopy(bert)\n","sd = bert.state_dict()\n","sd['blocks.11.mlp.W_out'] = W_edit\n","bert_updated.load_state_dict(sd)"]},{"cell_type":"markdown","metadata":{"id":"3PkdR4OCpOPC"},"source":["# Evaluation Val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95930,"status":"ok","timestamp":1716411791889,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"aL54Tm_CpM6j","outputId":"0a229a05-5332-4f1c-8b3d-64ac398593a3"},"outputs":[],"source":["LOGITS_EDIT_VAL = {f'y{y_idx}':{f'a{a_idx}':[] for a_idx in unique_a} for y_idx in unique_y}\n","dataset=val_dataset\n","\n","for Y_CURR in unique_y:\n","    for A_CURR in unique_a:\n","        print(f'y{Y_CURR}', f'a{A_CURR}')\n","        val_loader = FastDataLoader(  dataset=dataset,\n","                              batch_size=32,\n","                              num_workers=1,\n","                              )\n","        train_minibatches_iterator = iter(val_loader)\n","\n","        for step in tqdm.tqdm(range(len(val_loader))):\n","\n","            total_group_members = np.sum([batch.shape[0] for batch in LOGITS_EDIT_VAL[f'y{Y_CURR}'][f'a{A_CURR}']])\n","            if total_group_members > per_group_repr:\n","                break\n","            i, x, y, a = next(train_minibatches_iterator)\n","\n","            A_MASK = (a == A_CURR)\n","            Y_MASK = (y == Y_CURR)\n","            MASK = A_MASK & Y_MASK\n","            x = x[MASK]\n","            input_ids = x[:,:,0].cuda()\n","            one_zero_attention_mask = x[:,:,1].cuda()\n","            token_type_ids = x[:,:,2].cuda()\n","\n","            with torch.no_grad():\n","                logits = bert_updated(input_ids, one_zero_attention_mask=one_zero_attention_mask, token_type_ids=token_type_ids)\n","                LOGITS_EDIT_VAL[f'y{Y_CURR}'][f'a{A_CURR}'].append(logits[:,0,:].detach().cpu())\n","            del logits\n","            torch.cuda.empty_cache()\n","\n","        LOGITS_EDIT_VAL[f'y{Y_CURR}'][f'a{A_CURR}'] = torch.cat(LOGITS_EDIT_VAL[f'y{Y_CURR}'][f'a{A_CURR}'])[:per_group_repr]"]},{"cell_type":"markdown","metadata":{"id":"OS-cNbbQklED"},"source":["## Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1716411791889,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"nlasHiTJkptF"},"outputs":[],"source":["# Initialize confusion matrices\n","conf_matrix_a0 = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=int)\n","conf_matrix_a1 = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=int)\n","\n","conf_matrix = {ai: np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=int) for ai in a_s}\n","\n","# Compute confusion matrix for a0 and a1\n","# for ai in a_s:\n","conf_matrix_dict = {}\n","\n","for ai in a_s:\n","    for true_label in range(NUM_CLASSES):\n","        logits_ai = LOGITS_EDIT_VAL[y_s[true_label]][ai]\n","        pred_labels_ai = logits_ai.argmax(dim=1).numpy()\n","        for pred_label in pred_labels_ai:\n","            conf_matrix[ai][true_label, pred_label] += 1\n","    conf_matrix_dict[ai] = pd.DataFrame(conf_matrix[ai], columns=[f'Pred y{i}' for i in range(NUM_CLASSES)], index=[f'True y{i}' for i in range(NUM_CLASSES)]).T / per_group_repr * 100\n","\n","accuracy_df = pd.concat(conf_matrix_dict, axis=1).round(2)\n","\n","### For Validation ###\n","accuracy_df_PATH = path_to_root + f'/results/ModelEdits/Final/ConfusionMatrixVal_{DATASET}_seed{SEED}'\n","accuracy_df.to_csv(accuracy_df_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":585,"status":"ok","timestamp":1716411792457,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"vTIzFQzNuxjA","outputId":"4c96a554-4b92-4f11-ff88-dd8c46b195c7"},"outputs":[],"source":["accuracy_df"]},{"cell_type":"markdown","metadata":{"id":"ErcQpPM8ua-2"},"source":["# Evaluation Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94714,"status":"ok","timestamp":1716409027507,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"P0LNXmoPuceU","outputId":"eb7bfcb8-bae0-41be-e9bf-1e3bf330270d"},"outputs":[],"source":["LOGITS_EDIT_TEST = {f'y{y_idx}':{f'a{a_idx}':[] for a_idx in unique_a} for y_idx in unique_y}\n","dataset=te_dataset\n","\n","for Y_CURR in unique_y:\n","    for A_CURR in unique_a:\n","        print(f'y{Y_CURR}', f'a{A_CURR}')\n","        val_loader = FastDataLoader(  dataset=dataset,\n","                              batch_size=32,\n","                              num_workers=1,\n","                              )\n","        train_minibatches_iterator = iter(val_loader)\n","\n","        for step in tqdm.tqdm(range(len(val_loader))):\n","\n","            total_group_members = np.sum([batch.shape[0] for batch in LOGITS_EDIT_TEST[f'y{Y_CURR}'][f'a{A_CURR}']])\n","            if total_group_members > per_group_repr:\n","                break\n","            i, x, y, a = next(train_minibatches_iterator)\n","\n","            A_MASK = (a == A_CURR)\n","            Y_MASK = (y == Y_CURR)\n","            MASK = A_MASK & Y_MASK\n","            x = x[MASK]\n","            input_ids = x[:,:,0].cuda()\n","            one_zero_attention_mask = x[:,:,1].cuda()\n","            token_type_ids = x[:,:,2].cuda()\n","\n","            with torch.no_grad():\n","                logits = bert_updated(input_ids, one_zero_attention_mask=one_zero_attention_mask, token_type_ids=token_type_ids)\n","                LOGITS_EDIT_TEST[f'y{Y_CURR}'][f'a{A_CURR}'].append(logits[:,0,:].detach().cpu())\n","            del logits\n","            torch.cuda.empty_cache()\n","\n","        LOGITS_EDIT_TEST[f'y{Y_CURR}'][f'a{A_CURR}'] = torch.cat(LOGITS_EDIT_TEST[f'y{Y_CURR}'][f'a{A_CURR}'])[:per_group_repr]"]},{"cell_type":"markdown","metadata":{"id":"tsAdVE90vgcV"},"source":["## Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":545,"status":"ok","timestamp":1716409309436,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"OVtzDdemvQUr"},"outputs":[],"source":["# Initialize confusion matrices\n","conf_matrix_a0 = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=int)\n","conf_matrix_a1 = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=int)\n","\n","conf_matrix = {ai: np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=int) for ai in a_s}\n","\n","# Compute confusion matrix for a0 and a1\n","# for ai in a_s:\n","conf_matrix_dict = {}\n","\n","for ai in a_s:\n","    for true_label in range(NUM_CLASSES):\n","        logits_ai = LOGITS_EDIT_TEST[y_s[true_label]][ai]\n","        pred_labels_ai = logits_ai.argmax(dim=1).numpy()\n","        for pred_label in pred_labels_ai:\n","            conf_matrix[ai][true_label, pred_label] += 1\n","    conf_matrix_dict[ai] = pd.DataFrame(conf_matrix[ai], columns=[f'Pred y{i}' for i in range(NUM_CLASSES)], index=[f'True y{i}' for i in range(NUM_CLASSES)]).T / per_group_repr * 100\n","\n","accuracy_df = pd.concat(conf_matrix_dict, axis=1).round(2)\n","\n","### For Test ###\n","accuracy_df_PATH = path_to_root + f'/results/ModelEdits/Final/ConfusionMatrixTest_{DATASET}_seed{SEED}'\n","accuracy_df.to_csv(accuracy_df_PATH)"]},{"cell_type":"markdown","metadata":{"id":"T5DVLTjxzUym"},"source":["# Save W_edit"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1716409062928,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"hUsOo1wBwtdn"},"outputs":[],"source":["W_edit_PATH = path_to_root + f'/results/ModelEdits/Final/W_edit_{DATASET}_seed{SEED}.pth'\n","torch.save(W_edit , W_edit_PATH)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN/Qs/rOZmW8g0X36oVEoO7","collapsed_sections":["03FcolRXu3D-","8trqjnsHBqft","_kycbc_ci9qU","YzYFunhMk3As","NdFsLSJp9Mbj","Vh5lF2vy9dLa"],"gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
