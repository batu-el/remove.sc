{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyNY72vkLp96UcsqeOCiW7wr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QWRQs-0jb7N7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715600626296,"user_tz":-60,"elapsed":3824,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"52383f97-b862-43b2-caca-db5c2fb82427"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive mounted.\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'\n","models_path = path_to_root + '/models'\n","representations_path = path_to_root + '/representations'"]},{"cell_type":"code","source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM\n","from reprshift.models.hparams import hparams_f, HPARAM_SEARCH\n","from reprshift.dataset.datasets import MultiNLI\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader"],"metadata":{"id":"LGBDxYLLcfJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hparams = hparams_f('ERM')\n","learning_rates = [lr for lr in HPARAM_SEARCH['lr']]\n","hparams, learning_rates"],"metadata":{"id":"DPxJSh0KcgKu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715600668192,"user_tz":-60,"elapsed":390,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"4bde6bc2-16c3-490f-8b2f-93fb5aebca74"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'batch_size': 32,\n","  'last_layer_dropout': 0.5,\n","  'optimizer': 'adamw',\n","  'weight_decay': 0.0001,\n","  'lr': 1e-05,\n","  'group_balanced': False,\n","  'num_training_steps': 30001,\n","  'num_warmup_steps': 0},\n"," [1e-06, 1e-05, 0.0001])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["device = \"cuda\"\n","train_weights = None\n","batch_size = hparams['batch_size']\n","\n","train_dataset = MultiNLI(data_path, 'tr', hparams)\n","train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                    weights=train_weights,\n","                                    batch_size=batch_size,\n","                                    num_workers=1)\n","steps_per_epoch = len(train_dataset) / batch_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-K6XhRZStm7","executionInfo":{"status":"ok","timestamp":1715612600046,"user_tz":-60,"elapsed":25334,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"9d15edc2-6171-434d-ee1d-366c5aeca628"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}]},{"cell_type":"code","source":["algorithm_name = 'ERM'\n","random_seeds = [0,1,2,3,4]\n","init_state_dict_path = lambda random_seed : models_path + f'/00_randominit/seed{random_seed}/sd_epoch0.pth'\n","state_dict_PATH = models_path + '/01_erm/hpselection/'\n","init_state_dict_path(0), state_dict_PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHJ4nK_7U7mN","executionInfo":{"status":"ok","timestamp":1715612601131,"user_tz":-60,"elapsed":4,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"90077891-45bc-4d15-8203-800211df98c4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation/models/00_randominit/seed0/sd_epoch0.pth',\n"," '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation/models/01_erm/hpselection/')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["[learning_rates[2]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pcXmtSxeok9","executionInfo":{"status":"ok","timestamp":1715612639687,"user_tz":-60,"elapsed":728,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"9e607006-fdf0-4b00-d47d-da5a72ad4f19"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.0001]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["start_step = 1\n","n_steps = 30001 #30001 #hparams['num_training_steps']\n","checkpoint_freq = 1000\n","train_losses = {}\n","\n","seed = 0\n","\n","for lr in [learning_rates[2]]:\n","    hparams['lr'] = lr\n","    print('Training Learning Rate:', hparams['lr'])\n","    algorithm = ERM(num_classes=3, num_attributes=2, hparams=hparams)\n","    algorithm.to(device)\n","    algorithm.load_state_dict(torch.load(init_state_dict_path(seed)))\n","    train_losses[seed] = []\n","\n","    train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                        weights=train_weights,\n","                                        batch_size=batch_size,\n","                                        num_workers=1)\n","    train_minibatches_iterator = iter(train_loader)\n","\n","    for step in tqdm.tqdm(range(start_step, n_steps)):\n","        ### Training Step ###\n","        i, x, y, a = next(train_minibatches_iterator)\n","        minibatch_device = (i, x.to(device), y.to(device), a.to(device))\n","        algorithm.train()\n","        step_vals = algorithm.update(minibatch_device, step)\n","        train_losses[seed].append(step_vals['loss'])\n","\n","        ### Evaluation ###\n","        if (step % checkpoint_freq == 0) or (step == n_steps - 1):\n","            epoch = int(step / checkpoint_freq)\n","            algorithm_state_dict = algorithm.state_dict()\n","            algorithm_state_dict_PATH = state_dict_PATH + f'lr{lr}/sd_epoch{epoch}.pth'\n","            torch.save(algorithm_state_dict, algorithm_state_dict_PATH)\n","\n","    loss_PATH = state_dict_PATH + f'Loss_{algorithm_name}_{seed}.pth'\n","    torch.save(train_losses, loss_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlT2KONYXKrw","outputId":"b8496f77-7187-408f-909c-0f966042e54e","executionInfo":{"status":"ok","timestamp":1715617606237,"user_tz":-60,"elapsed":4960450,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Learning Rate: 0.0001\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","100%|██████████| 30000/30000 [1:22:38<00:00,  6.05it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JKWhlb_ye3NG"},"execution_count":null,"outputs":[]}]}