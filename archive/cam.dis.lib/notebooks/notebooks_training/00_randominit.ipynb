{"cells":[{"cell_type":"markdown","metadata":{"id":"qc4v8SN-6XmL"},"source":["# MultiNLI: Randomly Initialize 3 Models\n","\n","The same random initializations will be used to train all models in the thesis. All results are reported as the mean of the 3 experiments, along with the standard deviations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPy9WnGpzt7d"},"outputs":[],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ez6BT_uY0TfB"},"outputs":[],"source":["import torch\n","from reprshift.learning.algorithms import ERM\n","\n","hparams = {'last_layer_dropout': 0.2,\n","           'lr' : 0.001,\n","           'weight_decay':  1e-4,\n","           'num_warmup_steps':0,\n","           'num_training_steps':30001,}\n","# algorithm.predict(x_array[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRrguTy73C9I"},"outputs":[],"source":["initial_states = {i : ERM(num_classes=3, num_attributes=2, hparams=hparams) for i in range(3)}\n","psuedo_epoch = 0\n","algorithm_name = '00_randominit'\n","for random_seed in initial_states:\n","    algorithm_state_dict = initial_states[random_seed].state_dict()\n","    models_path = path_to_root + '/models/'\n","    algorithm_state_dict_PATH = models_path + f'/00_randominit/seed{random_seed}/sd_epoch{psuedo_epoch}.pth'\n","    print(algorithm_state_dict_PATH)\n","    torch.save(algorithm_state_dict, algorithm_state_dict_PATH)"]},{"cell_type":"markdown","metadata":{"id":"0xdMmZSg6dn2"},"source":["## Check Classifiers are Different"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZrFhCEe3uR9"},"outputs":[],"source":["classifier_weight = [initial_states[i].state_dict()['network.1.classifier.weight'] for i in initial_states]\n","classifier_bias = [initial_states[i].state_dict()['network.1.classifier.bias'] for i in initial_states]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qb6hF3_06QAi"},"outputs":[],"source":["import numpy as np\n","res = np.zeros([3,3])\n","\n","for i in range(3):\n","  for j in range(3):\n","    res[i][j] = ((classifier_weight[i] == classifier_weight[j]) == False).sum().item()\n","res\n","\n","### Expected: ###\n","# array([[   0., 1536., 1536.],\n","#        [1536.,    0., 1536.],\n","#        [1536., 1536.,    0.]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnSA9Wo039nf"},"outputs":[],"source":["import numpy as np\n","res = np.zeros([3,3])\n","\n","for i in range(3):\n","  for j in range(3):\n","    res[i][j] = ((classifier_bias[i] == classifier_bias[j]) == False).sum().item()\n","res\n","\n","### Expected: ###\n","# array([[0., 2., 2.],\n","#        [2., 0., 2.],\n","#        [2., 2., 0.]])"]},{"cell_type":"markdown","metadata":{"id":"rEEpxqd86n7m"},"source":["## Check Transformer Layers are the Same"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mu_oVNNb2CvN"},"outputs":[],"source":["layers_f =  lambda layer_name: [initial_states[i].state_dict()[layer_name] for i in initial_states]\n","\n","def compare_layer(layer_name):\n","    layers = layers_f(layer_name)\n","    res = np.zeros([3,3])\n","    for i in range(3):\n","        for j in range(3):\n","          res[i][j] = ((layers[i] == layers[j]) == False).sum().item()\n","    return res\n","\n","different_values = []\n","for layer_name in initial_states[i].state_dict():\n","    different_values.append(compare_layer(layer_name).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFtaN1FE7RbL"},"outputs":[],"source":["### Expected: All 0 except the last 2 elements (46080.0, 60.0) ###\n","different_values"]},{"cell_type":"markdown","metadata":{"id":"jAcJnTuKy0w6"},"source":["# CivilComments: Randomly Initialize 3 Models\n","\n","The same random initializations will be used to train all models in the thesis. All results are reported as the mean of the 3 experiments, along with the standard deviations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMzqpaJVy0w7"},"outputs":[],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6c2PLsQy0w7"},"outputs":[],"source":["import torch\n","from reprshift.learning.algorithms import ERM\n","\n","hparams = {'last_layer_dropout': 0.2,\n","           'lr' : 0.001,\n","           'weight_decay':  1e-4,\n","           'num_warmup_steps':0,\n","           'num_training_steps':30001,}\n","# algorithm.predict(x_array[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4sA6QvKy0w7"},"outputs":[],"source":["initial_states = {i : ERM(num_classes=2, num_attributes=8, hparams=hparams) for i in range(3)}\n","psuedo_epoch = 0\n","algorithm_name = '00_randominit'\n","for random_seed in initial_states:\n","    algorithm_state_dict = initial_states[random_seed].state_dict()\n","    models_path = path_to_root + '/models_civilcomments'\n","    algorithm_state_dict_PATH = models_path + f'/00_randominit/seed{random_seed}/sd_epoch{psuedo_epoch}.pth'\n","    print(algorithm_state_dict_PATH)\n","    torch.save(algorithm_state_dict, algorithm_state_dict_PATH)"]},{"cell_type":"markdown","metadata":{"id":"tR2GFkaIy0w7"},"source":["## Check Classifiers are Different"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPhVh4W4y0w8"},"outputs":[],"source":["classifier_weight = [initial_states[i].state_dict()['network.1.classifier.weight'] for i in initial_states]\n","classifier_bias = [initial_states[i].state_dict()['network.1.classifier.bias'] for i in initial_states]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1OU9vIBy0w8"},"outputs":[],"source":["import numpy as np\n","res = np.zeros([3,3])\n","\n","for i in range(3):\n","  for j in range(3):\n","    res[i][j] = ((classifier_weight[i] == classifier_weight[j]) == False).sum().item()\n","res\n","\n","### Expected: ###\n","# array([[   0., 1536., 1536.],\n","#        [1536.,    0., 1536.],\n","#        [1536., 1536.,    0.]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwatZgKEy0w8"},"outputs":[],"source":["import numpy as np\n","res = np.zeros([3,3])\n","\n","for i in range(3):\n","  for j in range(3):\n","    res[i][j] = ((classifier_bias[i] == classifier_bias[j]) == False).sum().item()\n","res\n","\n","### Expected: ###\n","# array([[0., 2., 2.],\n","#        [2., 0., 2.],\n","#        [2., 2., 0.]])"]},{"cell_type":"markdown","metadata":{"id":"OAQd0x5qy0w8"},"source":["## Check Transformer Layers are the Same"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDxR43HVy0w8"},"outputs":[],"source":["layers_f =  lambda layer_name: [initial_states[i].state_dict()[layer_name] for i in initial_states]\n","\n","def compare_layer(layer_name):\n","    layers = layers_f(layer_name)\n","    res = np.zeros([3,3])\n","    for i in range(3):\n","        for j in range(3):\n","          res[i][j] = ((layers[i] == layers[j]) == False).sum().item()\n","    return res\n","\n","different_values = []\n","for layer_name in initial_states[i].state_dict():\n","    different_values.append(compare_layer(layer_name).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bI6UJZZ7y0w8"},"outputs":[],"source":["### Expected: All 0 except the last 2 elements (9216.0, 12.0) ###\n","different_values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTmB8m680EiJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNCBlmz83EWxlomoEWE7Cdn","gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
