{"cells":[{"cell_type":"markdown","metadata":{"id":"8trqjnsHBqft"},"source":["# Setup"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6060,"status":"ok","timestamp":1716080648406,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JT1BvkRYBuFX","outputId":"38fbfd65-66ff-4838-958b-d361b9d9d09a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Drive mounted.\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716080648406,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bW4KeHLnDSuu"},"outputs":[],"source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM, GroupDRO, Focal, Algorithm\n","from reprshift.models.hparams import hparams_f\n","from reprshift.dataset.datasets import MultiNLI, CivilComments\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader"]},{"cell_type":"markdown","metadata":{"id":"u5J7zSlY4Zqc"},"source":["# JTT Implementation"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716080648406,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"nrvvEq534ZHO"},"outputs":[],"source":["## Based on https://github.com/YyzHarry/SubpopBench\n","\n","### Algorithm 6: JTT ###\n","class AbstractTwoStage(Algorithm):\n","    def __init__(self, num_classes, num_attributes, hparams):\n","        super().__init__(num_classes, num_attributes, hparams)\n","        self.stage1_model = ERM(num_classes, num_attributes, hparams)\n","        self.first_stage_step_frac = hparams['first_stage_step_frac']\n","        self.switch_step = int(self.first_stage_step_frac * hparams['num_training_steps'])\n","        self.cur_model = self.stage1_model\n","        self.stage2_model = None    # implement in child classes\n","\n","    def update(self, minibatch, step):\n","        all_i, all_x, all_y, all_a = minibatch\n","        if step < self.switch_step:\n","            self.cur_model = self.stage1_model\n","            self.cur_model.train()\n","            loss = self.stage1_model._compute_loss(all_i, all_x, all_y, all_a, step)\n","        else:\n","            self.cur_model = self.stage2_model\n","            self.cur_model.train()\n","            self.stage1_model.eval()\n","            loss = self.stage2_model._compute_loss(all_i, all_x, all_y, all_a, step, self.stage1_model)\n","\n","        self.cur_model.optimizer.zero_grad()\n","        loss.backward()\n","        if self.cur_model.clip_grad:\n","            torch.nn.utils.clip_grad_norm_(self.cur_model.network.parameters(), 1.0)\n","        self.cur_model.optimizer.step()\n","\n","        if self.cur_model.lr_scheduler is not None:\n","            self.cur_model.lr_scheduler.step()\n","\n","        self.cur_model.network.zero_grad()\n","        return {'loss': loss.item()}\n","\n","    def return_feats(self, x):\n","        return self.cur_model.featurizer(x)\n","\n","    def predict(self, x):\n","        return self.cur_model.network(x)\n","\n","class JTT_Stage2(ERM):\n","    def __init__(self, num_classes, num_attributes, hparams):\n","        super().__init__(num_classes, num_attributes, hparams)\n","\n","    def _compute_loss(self, i, x, y, a, step, stage1_model):\n","        with torch.no_grad():\n","            predictions = stage1_model.predict(x)\n","\n","        if predictions.squeeze().ndim == 1:\n","            wrong_predictions = (predictions > 0).detach().ne(y).float()\n","        else:\n","            wrong_predictions = predictions.argmax(1).detach().ne(y).float()\n","\n","        weights = torch.ones(wrong_predictions.shape).to(x.device).float()\n","        weights[wrong_predictions == 1] = self.hparams[\"jtt_lambda\"]\n","\n","        return (self.loss(self.predict(x), y) * weights).mean()\n","\n","class JTT(AbstractTwoStage):\n","    \"\"\"\n","    Just-train-twice (JTT) [https://arxiv.org/pdf/2107.09044.pdf]\n","    \"\"\"\n","    def __init__(self, num_classes, num_attributes, hparams):\n","        super().__init__(num_classes, num_attributes, hparams)\n","        self.stage2_model = JTT_Stage2(num_classes, num_attributes, hparams)"]},{"cell_type":"markdown","metadata":{"id":"yOFYFzDCBwcm"},"source":["# Data"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716080648406,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"zmBfh47bCgJi","outputId":"aae00574-fcde-4032-d457-fb7704763261"},"outputs":[{"data":{"text/plain":["{'batch_size': 32,\n"," 'last_layer_dropout': 0.5,\n"," 'optimizer': 'adamw',\n"," 'weight_decay': 0.0001,\n"," 'lr': 1e-05,\n"," 'group_balanced': False,\n"," 'num_training_steps': 30001,\n"," 'num_warmup_steps': 0,\n"," 'first_stage_step_frac': 0.5,\n"," 'jtt_lambda': 10}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["hparams = hparams_f('JTT')\n","hparams"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716080651211,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"YY0iS9t1u8Zd"},"outputs":[],"source":["device = \"cuda\"\n","train_weights = None\n","batch_size = hparams['batch_size']"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24216,"status":"ok","timestamp":1716080729097,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bpKbj3leBy8p","outputId":"c6537beb-edaf-4bf4-8916-11bf7eaf96de"},"outputs":[{"name":"stdout","output_type":"stream","text":["MultiNLI\n"]}],"source":["DATASET = 'MultiNLI'  # 'CivilComments' , 'MultiNLI'\n","\n","if DATASET == 'MultiNLI':\n","    NUM_CLASSES = 3\n","    NUM_ATTRIBUTES = 2\n","    train_dataset = MultiNLI(data_path, 'tr', hparams)\n","    models_path = path_to_root + '/models/models_mnli'\n","    print(DATASET)\n","elif DATASET  == 'CivilComments':\n","    NUM_CLASSES = 2\n","    NUM_ATTRIBUTES = 8\n","    train_dataset = CivilComments(data_path, 'tr', hparams, granularity=\"fine\")\n","    models_path = path_to_root + '/models/models_civilcomments'\n","    print(DATASET)\n","else:\n","    print('Dataset Not Implemented')"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":390,"status":"ok","timestamp":1716080771644,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"vaRe1H3G3Qem"},"outputs":[],"source":["train_loader  = InfiniteDataLoader(  dataset=train_dataset,\n","                                    weights=train_weights,\n","                                    batch_size=batch_size,\n","                                    num_workers=1)\n","steps_per_epoch = len(train_dataset) / batch_size"]},{"cell_type":"markdown","metadata":{"id":"wcXHpw2dB0VV"},"source":["# Model"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1265,"status":"ok","timestamp":1716080774619,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"nBJ-qyGsB08z"},"outputs":[],"source":["algorithm_name = 'JTT'\n","random_seeds = [1,2] #[0,1,2]\n","init_state_dict_path = lambda random_seed : models_path + f'/00_randominit/seed{random_seed}/sd_epoch0.pth'\n","state_dict_PATH = models_path + '/06_jtt/'"]},{"cell_type":"markdown","metadata":{"id":"7KIXqJyvB1g0"},"source":["# Training"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11648263,"status":"ok","timestamp":1716092425795,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"6qZBmY3jB2ly","outputId":"30dfe636-fdd6-4ef5-aa47-2eb2b6bf3808"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Seed: 1\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","100%|██████████| 30000/30000 [1:36:49<00:00,  5.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Seed: 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 30000/30000 [1:36:47<00:00,  5.17it/s]\n"]}],"source":["start_step = 1\n","n_steps = 30001 #hparams['num_training_steps']\n","checkpoint_freq = 1000\n","train_losses = {}\n","\n","for seed in random_seeds:\n","    print('Training Seed:' , seed)\n","    algorithm = JTT(num_classes=NUM_CLASSES, num_attributes=NUM_ATTRIBUTES, hparams=hparams)\n","    algorithm.to(device)\n","    ### Matching the Keys ###\n","    sd_init = torch.load(init_state_dict_path(seed))\n","    sd_init_matched = {f'stage1_model.{key}' :sd_init[key]  for key in sd_init.keys()}\n","    sd_algorithm = algorithm.state_dict()\n","    for key in sd_init_matched:\n","        sd_algorithm[key] = sd_init_matched[key]\n","    algorithm.load_state_dict(sd_algorithm)\n","    #########################\n","    train_losses[seed] = []\n","\n","    train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                        weights=train_weights,\n","                                        batch_size=batch_size,\n","                                        num_workers=1)\n","    train_minibatches_iterator = iter(train_loader)\n","\n","    for step in tqdm.tqdm(range(start_step, n_steps)):\n","        ### Training Step ###\n","        i, x, y, a = next(train_minibatches_iterator)\n","        minibatch_device = (i, x.to(device), y.to(device), a.to(device))\n","        algorithm.train()\n","        step_vals = algorithm.update(minibatch_device, step)\n","        train_losses[seed].append(step_vals['loss'])\n","\n","        ### Evaluation ###\n","        if (step % checkpoint_freq == 0) or (step == n_steps - 1):\n","            epoch = int(step / checkpoint_freq)\n","            algorithm_state_dict = algorithm.state_dict()\n","            algorithm_state_dict_PATH = state_dict_PATH + f'seed{seed}/sd_epoch{epoch}.pth'\n","            torch.save(algorithm_state_dict, algorithm_state_dict_PATH)\n","\n","    loss_PATH = state_dict_PATH + f'losses/Loss_{algorithm_name}_{seed}.pth'\n","    torch.save(train_losses, loss_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQvISitWLORM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM/VLnQbuWzVAfJ7DzZ4dV6","gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
