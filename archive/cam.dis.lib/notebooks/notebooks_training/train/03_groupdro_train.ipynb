{"cells":[{"cell_type":"markdown","metadata":{"id":"8trqjnsHBqft"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24186,"status":"ok","timestamp":1716054930237,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"JT1BvkRYBuFX","outputId":"61b47627-8aef-4440-d2bb-2b8e7ea2573a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Drive mounted.\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path_to_root = '/content/drive/My Drive/Colab Notebooks/BatuEl_Dissertation'\n","sys.path.append(path_to_root)\n","print(\"Drive mounted.\")\n","\n","data_path = path_to_root + '/data'"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":12966,"status":"ok","timestamp":1716054943200,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bW4KeHLnDSuu"},"outputs":[],"source":["import torch\n","import tqdm\n","from reprshift.learning.algorithms import ERM, GroupDRO, Focal\n","from reprshift.models.hparams import hparams_f\n","from reprshift.dataset.datasets import MultiNLI, CivilComments\n","from reprshift.dataset.dataloaders import InfiniteDataLoader, FastDataLoader"]},{"cell_type":"markdown","metadata":{"id":"yOFYFzDCBwcm"},"source":["# Data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1716074634755,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"zmBfh47bCgJi","outputId":"9a11a5f2-5d30-4cbb-b5fd-d7d4e070d93b"},"outputs":[{"data":{"text/plain":["{'batch_size': 32,\n"," 'last_layer_dropout': 0.5,\n"," 'optimizer': 'adamw',\n"," 'weight_decay': 0.0001,\n"," 'lr': 1e-05,\n"," 'group_balanced': False,\n"," 'num_training_steps': 30001,\n"," 'num_warmup_steps': 0,\n"," 'groupdro_eta': 0.01}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["hparams = hparams_f('GroupDRO')\n","hparams"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716074638378,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"BBEZUSxmu4eK"},"outputs":[],"source":["device = \"cuda\"\n","train_weights = None\n","batch_size = hparams['batch_size']"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30236,"status":"ok","timestamp":1716074673261,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"99yoGwtzwAqa","outputId":"564ab6c8-36d9-4159-f27a-30bd5596aed2"},"outputs":[{"name":"stdout","output_type":"stream","text":["MultiNLI\n"]}],"source":["DATASET = 'MultiNLI'  # 'CivilComments' , 'MultiNLI'\n","\n","if DATASET == 'MultiNLI':\n","    NUM_CLASSES = 3\n","    NUM_ATTRIBUTES = 2\n","    train_dataset = MultiNLI(data_path, 'tr', hparams)\n","    models_path = path_to_root + '/models/models_mnli'\n","    print(DATASET)\n","elif DATASET  == 'CivilComments':\n","    NUM_CLASSES = 2\n","    NUM_ATTRIBUTES = 8\n","    train_dataset = CivilComments(data_path, 'tr', hparams, granularity=\"fine\")\n","    models_path = path_to_root + '/models/models_civilcomments'\n","    print(DATASET)\n","else:\n","    print('Dataset Not Implemented')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716074673261,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"bpKbj3leBy8p","outputId":"64e82214-ce45-49a3-bf0f-1964fb3e00e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}],"source":["### Dataloader ###\n","train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                    weights=train_weights,\n","                                    batch_size=batch_size,\n","                                    num_workers=1)\n","steps_per_epoch = len(train_dataset) / batch_size"]},{"cell_type":"markdown","metadata":{"id":"wcXHpw2dB0VV"},"source":["# Model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":432,"status":"ok","timestamp":1716074686313,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"nBJ-qyGsB08z"},"outputs":[],"source":["algorithm_name = 'GroupDRO'\n","random_seeds = [1,2] #[0,1,2]\n","init_state_dict_path = lambda random_seed : models_path + f'/00_randominit/seed{random_seed}/sd_epoch0.pth'\n","state_dict_PATH = models_path + '/03_groupdro/'"]},{"cell_type":"markdown","metadata":{"id":"MsmgCFd6NyCi"},"source":["# Training"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4421089,"status":"ok","timestamp":1716084832214,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":-60},"id":"PzkmxeUeNxBD","outputId":"9f38aa3a-24dc-4b33-d95a-ab8a2237b4ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Seed: 1\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","100%|██████████| 30000/30000 [1:24:19<00:00,  5.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Seed: 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 30000/30000 [1:24:23<00:00,  5.93it/s]\n"]}],"source":["start_step = 1\n","n_steps = 30001 #hparams['num_training_steps']\n","checkpoint_freq = 1000\n","train_losses = {}\n","\n","for seed in random_seeds:\n","    print('Training Seed:' , seed)\n","    algorithm = GroupDRO(num_classes=NUM_CLASSES, num_attributes=NUM_ATTRIBUTES, hparams=hparams)\n","    algorithm.to(device)\n","    init_state_dict = torch.load(init_state_dict_path(seed))\n","    init_state_dict['q'] = algorithm.state_dict()['q']\n","    algorithm.load_state_dict(init_state_dict)\n","    train_losses[seed] = []\n","\n","    train_loader = InfiniteDataLoader(  dataset=train_dataset,\n","                                        weights=train_weights,\n","                                        batch_size=batch_size,\n","                                        num_workers=1)\n","    train_minibatches_iterator = iter(train_loader)\n","\n","    for step in tqdm.tqdm(range(start_step, n_steps)):\n","        ### Training Step ###\n","        i, x, y, a = next(train_minibatches_iterator)\n","        minibatch_device = (i, x.to(device), y.to(device), a.to(device))\n","        algorithm.train()\n","        step_vals = algorithm.update(minibatch_device, step)\n","        train_losses[seed].append(step_vals['loss'])\n","\n","        ### Evaluation ###\n","        if (step % checkpoint_freq == 0) or (step == n_steps - 1):\n","            epoch = int(step / checkpoint_freq)\n","            algorithm_state_dict = algorithm.state_dict()\n","            algorithm_state_dict_PATH = state_dict_PATH + f'seed{seed}/sd_epoch{epoch}.pth'\n","            torch.save(algorithm_state_dict, algorithm_state_dict_PATH)\n","\n","    loss_PATH = state_dict_PATH + f'losses/Loss_{algorithm_name}_{seed}.pth'\n","    torch.save(train_losses, loss_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1wXIHvSBbXm"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPHLGsuoGM4tJypb1xC84n1","gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
